{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHO5Ta3+tWJuqA1hQ59QEW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakshay-batra712/Lakshay_Batra_102303743_UML501/blob/main/Assignment4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iHk7Li3fUudg"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_URL = \"http://books.toscrape.com/catalogue/\"\n",
        "TOTAL_PAGES = 50\n",
        "\n",
        "def get_data_from_page(page_num):\n",
        "    page_data = []\n",
        "    current_page_url = f\"{BASE_URL}page-{page_num}.html\"\n",
        "\n",
        "    response = requests.get(current_page_url)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "    books = soup.find_all(\"article\", class_=\"product_pod\")\n",
        "    if not books:\n",
        "        return []\n",
        "\n",
        "    for book in books:\n",
        "        title_element = book.h3.a\n",
        "        title = title_element[\"title\"] if title_element else 'NaN'\n",
        "\n",
        "        price_element = book.find(\"p\", class_=\"price_color\")\n",
        "        price = price_element.get_text(strip=True) if price_element else 'NaN'\n",
        "\n",
        "        availability_element = book.find(\"p\", class_=\"instock availability\")\n",
        "        availability = availability_element.get_text(strip=True) if availability_element else 'NaN'\n",
        "\n",
        "        rating_element = book.find(\"p\", class_=\"star-rating\")\n",
        "        star_rating = rating_element[\"class\"][1] if rating_element and len(rating_element[\"class\"]) > 1 else 'NaN'\n",
        "\n",
        "        page_data.append({\n",
        "            \"Title\": title,\n",
        "            \"Price\": price,\n",
        "            \"Availability\": availability,\n",
        "            \"Star Rating\": star_rating\n",
        "        })\n",
        "\n",
        "    return page_data"
      ],
      "metadata": {
        "id": "-9ATOVGoU8Lh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_data = []\n",
        "for page in range(1, TOTAL_PAGES + 1):\n",
        "  all_data.extend(get_data_from_page(page))\n",
        "\n",
        "df = pd.DataFrame(all_data)\n",
        "\n",
        "if not df.empty:\n",
        "    df.to_csv('book_data.csv')"
      ],
      "metadata": {
        "id": "A8WnV6bEU_wF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
        "\n",
        "driver = webdriver.Chrome(options=options)\n",
        "driver.get(\"https://www.imdb.com/chart/top/\")\n",
        "\n",
        "wait = WebDriverWait(driver, 20)\n",
        "list_container = wait.until(\n",
        "    EC.presence_of_element_located((By.CSS_SELECTOR, \"ul.ipc-metadata-list\"))\n",
        ")\n",
        "movies = list_container.find_elements(By.TAG_NAME, \"li\")\n",
        "\n",
        "movies_data = []\n",
        "for movie_item in movies:\n",
        "    title_text = movie_item.find_element(By.CSS_SELECTOR, \"h3.ipc-title__text\").text\n",
        "    rank_str, title = title_text.split(\". \", 1)\n",
        "\n",
        "    metadata_items = movie_item.find_elements(By.CSS_SELECTOR, \"span.cli-title-metadata-item\")\n",
        "    year_str = metadata_items[0].text\n",
        "\n",
        "    rating_str = movie_item.find_element(By.CSS_SELECTOR, \"span.ipc-rating-star\").text.split(\"\\n\")[0]\n",
        "\n",
        "    movies_data.append({\n",
        "        \"Rank\": int(rank_str),\n",
        "        \"Movie Title\": title,\n",
        "        \"Year of Release\": int(year_str),\n",
        "        \"IMDB Rating\": float(rating_str)\n",
        "    })\n",
        "\n",
        "driver.quit()\n",
        "\n",
        "df = pd.DataFrame(movies_data)\n",
        "df = df.sort_values(by=\"Rank\").reset_index(drop=True)\n",
        "df.to_csv(\"imdb_top250.csv\", index=False, encoding='utf-8')\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOePRy6AVAHZ",
        "outputId": "c85f0395-885d-4ae4-c48e-cf803eb9b196"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Rank               Movie Title  Year of Release  IMDB Rating\n",
            "0       1  The Shawshank Redemption             1994          9.3\n",
            "1       2             The Godfather             1972          9.2\n",
            "2       3           The Dark Knight             2008          9.1\n",
            "3       4     The Godfather Part II             1974          9.0\n",
            "4       5              12 Angry Men             1957          9.0\n",
            "..    ...                       ...              ...          ...\n",
            "245   246        Gangs of Wasseypur             2012          8.2\n",
            "246   247             Into the Wild             2007          8.0\n",
            "247   248                  The Help             2011          8.1\n",
            "248   249             Groundhog Day             1993          8.0\n",
            "249   250                  Drishyam             2015          8.2\n",
            "\n",
            "[250 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_temp_as_float(temp):\n",
        "\n",
        "    value = temp.replace(\"°C\", \"\").replace(\"°F\", \"\").strip()\n",
        "\n",
        "    value = value.replace(\"\\u00a0\", \"\").replace(\"\\xa0\", \"\")\n",
        "    return float(value)\n",
        "\n",
        "url = \"https://www.timeanddate.com/weather/\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "tds = soup.find_all('td')\n",
        "results = []\n",
        "current_city = None\n",
        "weather_condition = \"\"\n",
        "\n",
        "for i, td in enumerate(tds):\n",
        "\n",
        "    if td.find('a'):\n",
        "        current_city = td.get_text(strip=True)\n",
        "\n",
        "        weather_condition = \"\"\n",
        "        for offset in range(1, 3):\n",
        "            if i + offset < len(tds):\n",
        "                img = tds[i + offset].find('img')\n",
        "                if img and img.get(\"alt\"):\n",
        "                    weather_condition = img[\"alt\"]\n",
        "                    break\n",
        "\n",
        "    elif 'rbi' in td.get('class', []) and current_city:\n",
        "        temp_str = td.get_text(strip=True)\n",
        "        try:\n",
        "            temp_float = extract_temp_as_float(temp_str)\n",
        "        except Exception as e:\n",
        "            temp_float = None\n",
        "        results.append({\n",
        "            \"City Name\": current_city,\n",
        "            \"Temperature\": temp_float,\n",
        "            \"Weather Condition\": weather_condition\n",
        "        })\n",
        "        current_city = None\n",
        "        weather_condition = \"\"\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv('weather.csv', index=False)\n"
      ],
      "metadata": {
        "id": "yNhNxAaoVDYm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pYxESSZcVdWY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}